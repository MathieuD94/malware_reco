{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mathieu\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3058: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Ce n'est pas un malware\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mathieu\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import lief\n",
    "import pefile\n",
    "import hashlib\n",
    "import array\n",
    "import math\n",
    "from joblib import load, dump\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "\n",
    "##Remplacer le fichier par l'executable par l'executable que vous voulez\n",
    "##tester\n",
    "binary = lief.parse(\"Teams_windows_x64.exe\")\n",
    "pe = pefile.PE(\"Teams_windows_x64.exe\")\n",
    "\n",
    "##Définition des fonction qui vont permettre l'extraction des données\n",
    "def SectionsMaxEntropy(binary):\n",
    "    cpt = 0\n",
    "    for s in binary.sections:\n",
    "        if cpt==0:\n",
    "            tmp = s.entropy\n",
    "            SectionsMaxEntropy = s.entropy  \n",
    "        else:\n",
    "            tmp = s.entropy\n",
    "            if (tmp >= SectionsMaxEntropy):\n",
    "                SectionsMaxEntropy=tmp\n",
    "        cpt = cpt+1\n",
    "    return SectionsMaxEntropy\n",
    "\n",
    "def ResourcesMinEntropy(pe):\n",
    "    resources= get_resources(pe)\n",
    "    ResourcesMinEntropy = min(resources)\n",
    "    return ResourcesMinEntropy\n",
    "    \n",
    "\n",
    "\n",
    "def get_entropy(data):\n",
    "    if len(data) == 0:\n",
    "        return 0.0\n",
    "    occurences = array.array('L', [0]*256)\n",
    "    for x in data:\n",
    "        occurences[x if isinstance(x, int) else ord(x)] += 1\n",
    "\n",
    "    entropy = 0\n",
    "    for x in occurences:\n",
    "        if x:\n",
    "            p_x = float(x) / len(data)\n",
    "            entropy -= p_x*math.log(p_x, 2)\n",
    "\n",
    "    return entropy\n",
    "\n",
    "def get_resources(pe):\n",
    "    #Extract resources :[entropy, size]\n",
    "    resources_entropy = []\n",
    "    if hasattr(pe, 'DIRECTORY_ENTRY_RESOURCE'):\n",
    "        try:\n",
    "            for resource_type in pe.DIRECTORY_ENTRY_RESOURCE.entries:\n",
    "                if hasattr(resource_type, 'directory'):\n",
    "                    for resource_id in resource_type.directory.entries:\n",
    "                        if hasattr(resource_id, 'directory'):\n",
    "                            for resource_lang in resource_id.directory.entries:\n",
    "                                data = pe.get_data(resource_lang.data.struct.OffsetToData, resource_lang.data.struct.Size)\n",
    "                                entropy = get_entropy(data)\n",
    "\n",
    "                                resources_entropy.append(entropy)\n",
    "        except Exception as e:\n",
    "            return resources_entropy\n",
    "    return resources_entropy\n",
    "\n",
    "##Regroupement des données extraitent\n",
    "def extract_info(binary,pe):\n",
    "    list_info = []\n",
    "    list_info.append(binary.header.sizeof_optional_header)\n",
    "    list_info.append(binary.optional_header.major_subsystem_version)\n",
    "    list_info.append(pe.OPTIONAL_HEADER.Subsystem)\n",
    "    list_info.append(binary.optional_header.dll_characteristics)\n",
    "    list_info.append(SectionsMaxEntropy(binary))\n",
    "    list_info.append(ResourcesMinEntropy(pe))\n",
    "    return(list_info)\n",
    "\n",
    "##Conversion de la liste d'infou sous Numpy\n",
    "extract_info = extract_info(binary,pe)\n",
    "info_numpy = np.array(extract_info)\n",
    "info_numpy_reshape = info_numpy.reshape(1, -1)\n",
    "\n",
    "##Lecture du dataset pour apprentissage\n",
    "malware_dataset = pd.read_csv(\"https://raw.githubusercontent.com/securitylab-repository/malware_classification/master/datasets/malware-detection/malwaredata.csv\",delimiter=',')\n",
    "\n",
    "##Creation des set d'entrainement et de test\n",
    "malware_train_set, malware_test_set = train_test_split(malware_dataset, test_size=0.9999, random_state=42)\n",
    "\n",
    "##Extraction des etiquettes\n",
    "malware_train = malware_train_set.drop(\"legitimate\", axis=1)\n",
    "labels_train = malware_train_set[\"legitimate\"].copy()\n",
    "malware_test = malware_test_set.drop(\"legitimate\", axis=1)\n",
    "labels_test = malware_test_set[\"legitimate\"].copy()\n",
    "#malware_train.info()\n",
    "#display(labels_train)\n",
    "\n",
    "\n",
    "#Suppression des features après analyse\n",
    "malware_feat = malware_train.drop(\"ID\", axis=1)\n",
    "malware_feat = malware_feat.drop(\"md5\", axis=1)\n",
    "malware_feat = malware_feat.drop(\"Unnamed: 57\", axis=1)\n",
    "malware_feat = malware_feat.drop(\"Machine\", axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#choix des features les plus corrélées avec la cible\n",
    "features = ['SizeOfOptionalHeader','MajorSubsystemVersion','Subsystem','DllCharacteristics'\n",
    "        \t,'SectionsMaxEntropy','ResourcesMinEntropy']\n",
    "#Transformation des dataset d'entrainement et de test\n",
    "#pour avoir seulement les features les plus corrélées avec la cible\n",
    "malware_feat_corr_train = pd.DataFrame(\n",
    "\tmalware_feat,\n",
    "\tcolumns=features,\n",
    "\tindex=malware_feat.index)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "   \t \n",
    "    \t('imputer', SimpleImputer(strategy=\"median\")),\n",
    "    \t('std_scaler', StandardScaler()),\n",
    "\t])\n",
    "\n",
    "##traitement du dataset d'entraînement\n",
    "malware_prepared_corr_train = num_pipeline.fit_transform(malware_feat_corr_train)\n",
    "\n",
    "##Initialisation de l'algo SVM\n",
    "svm= SVC(kernel=\"rbf\", degree=1, coef0=0.1, C=100)\n",
    "\n",
    "# Entraînement\n",
    "svm.fit(malware_feat_corr_train,labels_train)\n",
    "\n",
    "\n",
    "prediction = svm.predict(info_numpy_reshape)\n",
    "\n",
    "## 1 : si c'est un malware\n",
    "## 0: si ce n'est pas un malware\n",
    "print(prediction[0])\n",
    "if prediction[0] == 0:\n",
    "    print(\"Ce n'est pas un malware\")\n",
    "elif prediction[0] == 1:\n",
    "    print(\"C'est un malware\")\n",
    "else:\n",
    "    print(\"Erreur\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lief\n",
    "import pefile\n",
    "import hashlib\n",
    "import array\n",
    "import math\n",
    "from joblib import load, dump\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "#import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "#from pandas.plotting import scatter_matrix\n",
    "from sklearn.impute import SimpleImputer\n",
    "#from sklearn.preprocessing import OrdinalEncoder\n",
    "#from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#from sklearn.compose import ColumnTransformer\n",
    "#from sklearn.linear_model import LinearRegression\n",
    "#from sklearn.metrics import mean_squared_error\n",
    "#from sklearn.tree import DecisionTreeRegressor\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "#from sklearn.ensemble import RandomForestRegressor\n",
    "#from sklearn.model_selection import GridSearchCV\n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import accuracy_score\n",
    "#from sklearn import model_selection\n",
    "#from sklearn import neighbors\n",
    "#from sklearn.model_selection import GridSearchCV\n",
    "#from sklearn.neighbors import KNeighborsClassifier\n",
    "#from sklearn.tree import DecisionTreeClassifier\n",
    "#from sklearn import metrics\n",
    "#from sklearn import tree\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "binary = lief.parse(\"SyncBackPro64_Setup(4).exe\")\n",
    "pe = pefile.PE(\"SyncBackPro64_Setup(4).exe\")\n",
    "\n",
    "def SectionsMaxEntropy(binary):\n",
    "\tcpt = 0\n",
    "\tfor s in binary.sections:\n",
    "    \tif cpt==0:\n",
    "        \ttmp = s.entropy\n",
    "        \tSectionsMaxEntropy = s.entropy  \n",
    "    \telse:\n",
    "        \ttmp = s.entropy\n",
    "        \tif (tmp >= SectionsMaxEntropy):\n",
    "            \tSectionsMaxEntropy=tmp\n",
    "    \tcpt = cpt+1\n",
    "\treturn SectionsMaxEntropy\n",
    "\n",
    "def ResourcesMinEntropy(pe):\n",
    "\tresources= get_resources(pe)\n",
    "\tResourcesMinEntropy = min(resources)\n",
    "\treturn ResourcesMinEntropy\n",
    "    \n",
    "\n",
    "\n",
    "def get_entropy(data):\n",
    "\tif len(data) == 0:\n",
    "    \treturn 0.0\n",
    "\toccurences = array.array('L', [0]*256)\n",
    "\tfor x in data:\n",
    "    \toccurences[x if isinstance(x, int) else ord(x)] += 1\n",
    "\n",
    "\tentropy = 0\n",
    "\tfor x in occurences:\n",
    "    \tif x:\n",
    "        \tp_x = float(x) / len(data)\n",
    "        \tentropy -= p_x*math.log(p_x, 2)\n",
    "\n",
    "\treturn entropy\n",
    "\n",
    "def get_resources(pe):\n",
    "\t#Extract resources :[entropy, size]\n",
    "\tresources_entropy = []\n",
    "\tif hasattr(pe, 'DIRECTORY_ENTRY_RESOURCE'):\n",
    "    \ttry:\n",
    "        \tfor resource_type in pe.DIRECTORY_ENTRY_RESOURCE.entries:\n",
    "            \tif hasattr(resource_type, 'directory'):\n",
    "                \tfor resource_id in resource_type.directory.entries:\n",
    "                    \tif hasattr(resource_id, 'directory'):\n",
    "                        \tfor resource_lang in resource_id.directory.entries:\n",
    "                            \tdata = pe.get_data(resource_lang.data.struct.OffsetToData, resource_lang.data.struct.Size)\n",
    "                            \tentropy = get_entropy(data)\n",
    "\n",
    "                            \tresources_entropy.append(entropy)\n",
    "    \texcept Exception as e:\n",
    "        \treturn resources_entropy\n",
    "\treturn resources_entropy\n",
    "\n",
    "\n",
    "def extract_info(binary,pe):\n",
    "\tlist_info = []\n",
    "\tlist_info.append(binary.header.sizeof_optional_header)\n",
    "\tlist_info.append(binary.optional_header.major_subsystem_version)\n",
    "\tlist_info.append(pe.OPTIONAL_HEADER.Subsystem)\n",
    "\tlist_info.append(binary.optional_header.dll_characteristics)\n",
    "\tlist_info.append(SectionsMaxEntropy(binary))\n",
    "\tlist_info.append(ResourcesMinEntropy(pe))\n",
    "\treturn(list_info)\n",
    "\n",
    "extract_info = extract_info(binary,pe)\n",
    "info_numpy = np.array(extract_info)\n",
    "info_numpy_reshape = info_numpy.reshape(1, -1)\n",
    "\n",
    "\n",
    "malware_dataset = pd.read_csv(\"https://raw.githubusercontent.com/securitylab-repository/malware_classification/master/datasets/malware-detection/malwaredata.csv\",delimiter=',')\n",
    "\n",
    "##Creation des set d'entrainement et de test\n",
    "malware_train_set, malware_test_set = train_test_split(malware_dataset, test_size=0.4, random_state=42)\n",
    "\n",
    "##Extraction des etiquettes\n",
    "malware_train = malware_train_set.drop(\"legitimate\", axis=1)\n",
    "labels_train = malware_train_set[\"legitimate\"].copy()\n",
    "malware_test = malware_test_set.drop(\"legitimate\", axis=1)\n",
    "labels_test = malware_test_set[\"legitimate\"].copy()\n",
    "#malware_train.info()\n",
    "#display(labels_train)\n",
    "\n",
    "\n",
    "#Suppression des features après analyse\n",
    "\n",
    "malware_feat = malware_train.drop(\"ID\", axis=1)\n",
    "malware_feat = malware_feat.drop(\"md5\", axis=1)\n",
    "malware_feat = malware_feat.drop(\"Unnamed: 57\", axis=1)\n",
    "malware_feat = malware_feat.drop(\"Machine\", axis=1)\n",
    "\n",
    "malware_feat_test = malware_test.drop(\"ID\", axis=1)\n",
    "malware_feat_test = malware_feat_test.drop(\"md5\", axis=1)\n",
    "malware_feat_test = malware_feat_test.drop(\"Unnamed: 57\", axis=1)\n",
    "malware_feat_test = malware_feat_test.drop(\"Machine\", axis=1)\n",
    "\n",
    "\n",
    "\n",
    "#choix des features les plus corrélées avec la cible\n",
    "features = ['SizeOfOptionalHeader','MajorSubsystemVersion','Subsystem','DllCharacteristics'\n",
    "        \t,'SectionsMaxEntropy','ResourcesMinEntropy']\n",
    "#Transformation des dataset d'entrainement et de test\n",
    "#pour avoir seulement les features les plus corrélées avec la cible\n",
    "malware_feat_corr_train = pd.DataFrame(\n",
    "\tmalware_feat,\n",
    "\tcolumns=features,\n",
    "\tindex=malware_feat.index)\n",
    "\n",
    "malware_feat_corr_test = pd.DataFrame(\n",
    "\tmalware_feat_test,\n",
    "\tcolumns=features,\n",
    "\tindex=malware_feat_test.index)\n",
    "\n",
    "\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "   \t \n",
    "    \t('imputer', SimpleImputer(strategy=\"median\")),\n",
    "    \t('std_scaler', StandardScaler()),\n",
    "\t])\n",
    "\n",
    "\n",
    "malware_prepared_corr_train = num_pipeline.fit_transform(malware_feat_corr_train)\n",
    "\n",
    "\n",
    "svm= SVC(kernel=\"rbf\", degree=1, coef0=0.1, C=100)\n",
    "\n",
    "# Entraînement\n",
    "svm.fit(malware_feat_corr_train,labels_train)\n",
    "\n",
    "#Evaluation de l'algo Knn\n",
    "final_predictions_svm = svm.predict(malware_feat_corr_test)\n",
    "\n",
    "#Calcul de la précision du modèle Knn\n",
    "acc_model_svm = accuracy_score(labels_test,final_predictions_svm)\n",
    "print(acc_model_svm)\n",
    "\n",
    "prediction = svm.predict(info_numpy_reshape)\n",
    "\n",
    "print(prediction)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
